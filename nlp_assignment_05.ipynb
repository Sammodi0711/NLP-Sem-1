{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcw4L+751fZSkWuWKqLZz1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sammodi0711/NLP-Sem-1/blob/main/nlp_assignment_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVmN4ZL5Cux4",
        "outputId": "db749291-cb61-45c8-f0a1-c8dc21053dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email: 'cheap price now'\n",
            "P(Spam | Email) = 0.935\n",
            "P(Ham  | Email) = 0.065\n",
            "Classification: Spam\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "emails = [\n",
        "    (\"Win money now\", \"Spam\"),\n",
        "    (\"Lowest price guaranteed\", \"Spam\"),\n",
        "    (\"Cheap meds available\", \"Spam\"),\n",
        "    (\"Hello friend how are you\", \"Ham\"),\n",
        "    (\"Let’s have lunch tomorrow\", \"Ham\"),\n",
        "    (\"Meeting schedule attached\", \"Ham\"),\n",
        "    (\"Win a free lottery ticket\", \"Spam\"),\n",
        "    (\"See you at the conference\", \"Ham\"),\n",
        "    (\"Project deadline reminder\", \"Ham\"),\n",
        "    (\"Cheap loans available\", \"Spam\"),\n",
        "]\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "spam_words = []\n",
        "ham_words = []\n",
        "for text, label in emails:\n",
        "    if label == \"Spam\":\n",
        "        spam_words.extend(tokenize(text))\n",
        "    else:\n",
        "        ham_words.extend(tokenize(text))\n",
        "\n",
        "vocab = set(spam_words + ham_words)\n",
        "\n",
        "spam_count = defaultdict(int)\n",
        "ham_count = defaultdict(int)\n",
        "for word in spam_words:\n",
        "    spam_count[word] += 1\n",
        "for word in ham_words:\n",
        "    ham_count[word] += 1\n",
        "\n",
        "total_spam_words = len(spam_words)\n",
        "total_ham_words = len(ham_words)\n",
        "\n",
        "p_spam = sum(1 for _, label in emails if label == \"Spam\") / len(emails)\n",
        "p_ham = 1 - p_spam\n",
        "\n",
        "def likelihood(word, label):\n",
        "    V = len(vocab)\n",
        "    if label == \"Spam\":\n",
        "        return (spam_count[word] + 1) / (total_spam_words + V)\n",
        "    else:\n",
        "        return (ham_count[word] + 1) / (total_ham_words + V)\n",
        "\n",
        "def classify(text):\n",
        "    words = tokenize(text)\n",
        "\n",
        "    log_prob_spam = math.log(p_spam)\n",
        "    log_prob_ham = math.log(p_ham)\n",
        "\n",
        "    for w in words:\n",
        "        log_prob_spam += math.log(likelihood(w, \"Spam\"))\n",
        "        log_prob_ham += math.log(likelihood(w, \"Ham\"))\n",
        "\n",
        "    prob_spam = math.exp(log_prob_spam)\n",
        "    prob_ham = math.exp(log_prob_ham)\n",
        "\n",
        "    total = prob_spam + prob_ham\n",
        "    return prob_spam/total, prob_ham/total\n",
        "\n",
        "test_email = \"cheap price now\"\n",
        "p_spam, p_ham = classify(test_email)\n",
        "\n",
        "print(f\"Email: '{test_email}'\")\n",
        "print(f\"P(Spam | Email) = {p_spam:.3f}\")\n",
        "print(f\"P(Ham  | Email) = {p_ham:.3f}\")\n",
        "print(\"Classification:\", \"Spam\" if p_spam > p_ham else \"Ham\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "emails = [\n",
        "    (\"Win money now\", \"Spam\"),\n",
        "    (\"Lowest price guaranteed\", \"Spam\"),\n",
        "    (\"Cheap meds available\", \"Spam\"),\n",
        "    (\"Hello friend how are you\", \"Ham\"),\n",
        "    (\"Let’s have lunch tomorrow\", \"Ham\"),\n",
        "    (\"Meeting schedule attached\", \"Ham\"),\n",
        "    (\"Win a free lottery ticket\", \"Spam\"),\n",
        "    (\"See you at the conference\", \"Ham\"),\n",
        "    (\"Project deadline reminder\", \"Ham\"),\n",
        "    (\"Cheap loans available\", \"Spam\"),\n",
        "]\n",
        "stopwords = {\"the\", \"is\", \"at\", \"a\", \"an\", \"how\", \"are\", \"let’s\", \"have\"}\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stopwords]\n",
        "    return tokens\n",
        "\n",
        "documents = [(preprocess(text), label) for text, label in emails]\n",
        "\n",
        "train_data = documents[:8]\n",
        "test_data = documents[8:]\n",
        "\n",
        "vocab = set()\n",
        "for words, _ in train_data:\n",
        "    vocab.update(words)\n",
        "V = len(vocab)\n",
        "\n",
        "word_count_spam = defaultdict(int)\n",
        "word_count_ham = defaultdict(int)\n",
        "spam_docs = ham_docs = 0\n",
        "\n",
        "for words, label in train_data:\n",
        "    if label == \"Spam\":\n",
        "        spam_docs += 1\n",
        "        for w in words:\n",
        "            word_count_spam[w] += 1\n",
        "    else:\n",
        "        ham_docs += 1\n",
        "        for w in words:\n",
        "            word_count_ham[w] += 1\n",
        "\n",
        "total_spam_words = sum(word_count_spam.values())\n",
        "total_ham_words = sum(word_count_ham.values())\n",
        "\n",
        "p_spam = spam_docs / len(train_data)\n",
        "p_ham = ham_docs / len(train_data)\n",
        "\n",
        "def likelihood(word, label):\n",
        "    if label == \"Spam\":\n",
        "        return (word_count_spam[word] + 1) / (total_spam_words + V)\n",
        "    else:\n",
        "        return (word_count_ham[word] + 1) / (total_ham_words + V)\n",
        "\n",
        "def classify(words):\n",
        "    log_prob_spam = math.log(p_spam)\n",
        "    log_prob_ham = math.log(p_ham)\n",
        "\n",
        "    for w in words:\n",
        "        log_prob_spam += math.log(likelihood(w, \"Spam\"))\n",
        "        log_prob_ham += math.log(likelihood(w, \"Ham\"))\n",
        "\n",
        "    return \"Spam\" if log_prob_spam > log_prob_ham else \"Ham\"\n",
        "\n",
        "correct = 0\n",
        "for words, label in test_data:\n",
        "    prediction = classify(words)\n",
        "    print(f\"Email: {' '.join(words)} | Actual: {label} | Predicted: {prediction}\")\n",
        "    if prediction == label:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / len(test_data)\n",
        "print(\"\\nAccuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9sidCl5DWzk",
        "outputId": "946100d9-8e70-4714-987c-118223aa3ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email: project deadline reminder | Actual: Ham | Predicted: Ham\n",
            "Email: cheap loans available | Actual: Spam | Predicted: Spam\n",
            "\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "emails = [\n",
        "    (\"Win money now\", \"Spam\"),\n",
        "    (\"Lowest price guaranteed\", \"Spam\"),\n",
        "    (\"Cheap meds available\", \"Spam\"),\n",
        "    (\"Hello friend how are you\", \"Ham\"),\n",
        "    (\"Let’s have lunch tomorrow\", \"Ham\"),\n",
        "    (\"Meeting schedule attached\", \"Ham\"),\n",
        "    (\"Win a free lottery ticket\", \"Spam\"),\n",
        "    (\"See you at the conference\", \"Ham\"),\n",
        "    (\"Project deadline reminder\", \"Ham\"),\n",
        "    (\"Cheap loans available\", \"Spam\"),\n",
        "]\n",
        "\n",
        "texts = [t for t, _ in emails]\n",
        "labels = [l for _, l in emails]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_bow, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_bow)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Predictions:\", y_pred)\n",
        "print(\"Actual:\", y_test)\n",
        "print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvarifo3E0zt",
        "outputId": "f7b9055f-62a4-4627-ca86-0b69cbcc0c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: ['Ham' 'Ham']\n",
            "Actual: ['Ham', 'Spam']\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    }
  ]
}